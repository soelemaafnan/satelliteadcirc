{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 10.3 GiB for an array with shape (2496, 553125) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m latitudes \u001b[38;5;241m=\u001b[39m nc_file\u001b[38;5;241m.\u001b[39mvariables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m][:]  \u001b[38;5;66;03m# Replace with your actual variable name\u001b[39;00m\n\u001b[1;32m     36\u001b[0m longitudes \u001b[38;5;241m=\u001b[39m nc_file\u001b[38;5;241m.\u001b[39mvariables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m][:]  \u001b[38;5;66;03m# Replace with your actual variable name\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m zeta \u001b[38;5;241m=\u001b[39m \u001b[43mnc_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzeta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Normalize longitudes from 0-360 to -180 to +180 if needed\u001b[39;00m\n\u001b[1;32m     40\u001b[0m longitudes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(longitudes \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m180\u001b[39m, longitudes \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m360\u001b[39m, longitudes)\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:4953\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 10.3 GiB for an array with shape (2496, 553125) and data type float64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "import netCDF4\n",
    "from noaa_coops import Station\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def calculate_rmse(true_values, predicted_values):\n",
    "    # Check if both arrays have more than 48 elements\n",
    "    if len(true_values) > 384 and len(predicted_values) > 384:\n",
    "        # Exclude the first 48 values\n",
    "        true_values = true_values[384:]\n",
    "        predicted_values = predicted_values[384:]\n",
    "    else:\n",
    "        # Not enough data points to exclude the first 48 values\n",
    "        # Handle this case as needed, for example, return np.nan or raise an error\n",
    "        return np.nan\n",
    "\n",
    "    # Handle cases where the lengths are different due to missing data\n",
    "    valid_mask = ~np.isnan(true_values) & ~np.isnan(predicted_values)\n",
    "    true_values, predicted_values = true_values[valid_mask], predicted_values[valid_mask]\n",
    "    \n",
    "    # Calculate and return RMSE\n",
    "    return sqrt(mean_squared_error(true_values, predicted_values))\n",
    "\n",
    "# Read the station details CSV file\n",
    "station_details = pd.read_csv('station_details.csv')\n",
    "\n",
    "# Load the NetCDF file\n",
    "nc_file = netCDF4.Dataset('/work2/07174/soelem/hopper/fort.63.nc', 'r')\n",
    "\n",
    "# Extract the latitude and longitude from the NetCDF file\n",
    "latitudes = nc_file.variables['y'][:]  # Replace with your actual variable name\n",
    "longitudes = nc_file.variables['x'][:]  # Replace with your actual variable name\n",
    "zeta = nc_file.variables['zeta'][:]\n",
    "\n",
    "# Normalize longitudes from 0-360 to -180 to +180 if needed\n",
    "longitudes = np.where(longitudes > 180, longitudes - 360, longitudes)\n",
    "\n",
    "# Create an array of tuples with the latitude and longitude\n",
    "points = np.column_stack((latitudes, longitudes))\n",
    "\n",
    "# Create a KDTree for quick nearest-neighbor lookup\n",
    "kdtree = cKDTree(points)\n",
    "\n",
    "# Prepare a list to hold RMSE values\n",
    "rmse_values = []\n",
    "\n",
    "# Loop through each station, find the closest point, and retrieve water level data\n",
    "for index, row in station_details.iterrows():\n",
    "    try:\n",
    "        station_id = row['Station ID']\n",
    "        \n",
    "        # Find the closest point for the current station's coordinates\n",
    "        _, closest_point_idx = kdtree.query([row['Latitude'], row['Longitude']])\n",
    "        \n",
    "        # Adjust the index for 0-based Python indexing\n",
    "        closest_point_idx_zero_based = closest_point_idx - 1\n",
    "        \n",
    "        # Retrieve 'zeta' variable data for the closest point\n",
    "        nc_zeta = zeta[384:, closest_point_idx_zero_based]\n",
    "        \n",
    "        # Delete the first 4 values and shift the remaining values up\n",
    "        nc_zeta_adjusted = np.delete(nc_zeta, np.s_[0:4])\n",
    "        \n",
    "        # Initialize the station object\n",
    "        station = Station(station_id)\n",
    "\n",
    "        # Try to retrieve water level data for the station\n",
    "        try:\n",
    "            station_data = station.get_data(\n",
    "                begin_date=\"20230716\",\n",
    "                end_date=\"20231031\",\n",
    "                product=\"hourly_height\",\n",
    "                datum=\"MSL\",\n",
    "                units=\"metric\",\n",
    "                time_zone=\"lst\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving data for station {station_id}: {e}\")\n",
    "            rmse_values.append(np.nan)  # Append a NaN value for stations with errors\n",
    "            continue  # Skip to the next iteration of the loop\n",
    "\n",
    "        # The index 't' is already in datetime format, so no conversion is necessary\n",
    "        station_df = pd.DataFrame(station_data)\n",
    "        \n",
    "        # Ensure nc_zeta_adjusted aligns with the time frame, accounting for the deleted entries\n",
    "        nc_zeta_series = pd.Series(nc_zeta_adjusted.flatten(), index=pd.date_range(start=\"2023-07-16 00:00:00\", periods=len(nc_zeta_adjusted), freq='H'))\n",
    "\n",
    "        # Resample or interpolate to ensure both series align on the same time index\n",
    "        station_df_resampled = station_df['v'].reindex(nc_zeta_series.index, method='nearest')\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        rmse = calculate_rmse(station_df_resampled.values, nc_zeta_series.values)\n",
    "        rmse_values.append(rmse)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch any other exception that might occur\n",
    "        print(f\"An unexpected error occurred for station {station_id}: {e}\")\n",
    "        rmse_values.append(np.nan)  # Append a NaN value for stations with errors\n",
    "        continue  # Skip to the next iteration of the loop\n",
    "\n",
    "# Add the RMSE values to the station_details DataFrame\n",
    "station_details['RMSE_without'] = rmse_values\n",
    "\n",
    "# Save the updated dataframe as \"rmse.csv\"\n",
    "station_details.to_csv('rmse_jason_highres_without.csv', index=False)\n",
    "\n",
    "# Close the NetCDF file\n",
    "nc_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "import netCDF4\n",
    "from noaa_coops import Station\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def calculate_rmse(true_values, predicted_values):\n",
    "    # Handle cases where the lengths are different due to missing data\n",
    "    if len(true_values) != len(predicted_values):\n",
    "        valid_mask = ~np.isnan(true_values) & ~np.isnan(predicted_values)\n",
    "        true_values, predicted_values = true_values[valid_mask], predicted_values[valid_mask]\n",
    "    return sqrt(mean_squared_error(true_values, predicted_values))\n",
    "\n",
    "# Read the station details CSV file\n",
    "station_details = pd.read_csv('station_details.csv')\n",
    "\n",
    "# Load the NetCDF file\n",
    "nc_file = netCDF4.Dataset('diff/swotfort.63.nc', 'r')\n",
    "\n",
    "# Extract the latitude and longitude from the NetCDF file\n",
    "latitudes = nc_file.variables['y'][:]  # Replace with your actual variable name\n",
    "longitudes = nc_file.variables['x'][:]  # Replace with your actual variable name\n",
    "zeta = nc_file.variables['zeta'][:]\n",
    "\n",
    "# Normalize longitudes from 0-360 to -180 to +180 if needed\n",
    "longitudes = np.where(longitudes > 180, longitudes - 360, longitudes)\n",
    "\n",
    "# Create an array of tuples with the latitude and longitude\n",
    "points = np.column_stack((latitudes, longitudes))\n",
    "\n",
    "# Create a KDTree for quick nearest-neighbor lookup\n",
    "kdtree = cKDTree(points)\n",
    "\n",
    "# Prepare a list to hold RMSE values\n",
    "rmse_values = []\n",
    "\n",
    "# Define the desired date range\n",
    "desired_start = pd.Timestamp(\"2023-09-22 00:00:00\")\n",
    "desired_end = pd.Timestamp(\"2023-09-23 23:00:00\")\n",
    "\n",
    "# Loop through each station, find the closest point, and retrieve water level data\n",
    "for index, row in station_details.iterrows():\n",
    "    try:\n",
    "        station_id = row['Station ID']\n",
    "        \n",
    "        # Find the closest point for the current station's coordinates\n",
    "        _, closest_point_idx = kdtree.query([row['Latitude'], row['Longitude']])\n",
    "        \n",
    "        # Adjust the index for 0-based Python indexing\n",
    "        closest_point_idx_zero_based = closest_point_idx - 1\n",
    "        \n",
    "        # Retrieve 'zeta' variable data for the closest point\n",
    "        nc_zeta = zeta[:, closest_point_idx_zero_based]\n",
    "        \n",
    "        # Delete the first 4 values and shift the remaining values up\n",
    "        nc_zeta_adjusted = np.delete(nc_zeta, np.s_[0:8])\n",
    "        \n",
    "        # Adjust NetCDF 'zeta' data to match the desired time range\n",
    "        nc_zeta_series = pd.Series(nc_zeta_adjusted.flatten(), index=pd.date_range(start=\"2023-09-11 04:00:00\", periods=len(nc_zeta_adjusted), freq='H'))\n",
    "        nc_zeta_filtered = nc_zeta_series[desired_start:desired_end]\n",
    "\n",
    "        # Initialize the station object\n",
    "        station = Station(station_id)\n",
    "\n",
    "        # Retrieve water level data for the station for the specified date range\n",
    "        station_data = station.get_data(\n",
    "            begin_date=desired_start.strftime(\"%Y%m%d\"),\n",
    "            end_date=desired_end.strftime(\"%Y%m%d\"),\n",
    "            product=\"hourly_height\",\n",
    "            datum=\"NAVD\",\n",
    "            units=\"metric\",\n",
    "            time_zone=\"lst\"\n",
    "        )\n",
    "\n",
    "        # The index 't' is already in datetime format, so no conversion is necessary\n",
    "        station_df = pd.DataFrame(station_data)\n",
    "        \n",
    "        # Resample or interpolate to ensure both series align on the same time index\n",
    "        station_df_resampled = station_df['v'].reindex(nc_zeta_filtered.index, method='nearest')\n",
    "\n",
    "        # Filter NOAA station data to match the same period\n",
    "        station_df_resampled_filtered = station_df_resampled[desired_start:desired_end]\n",
    "\n",
    "        # Calculate RMSE for the filtered period\n",
    "        rmse = calculate_rmse(station_df_resampled_filtered.values, nc_zeta_filtered.values)\n",
    "        rmse_values.append(rmse)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred for station {station_id}: {e}\")\n",
    "        rmse_values.append(np.nan)  # Append a NaN value for stations with errors\n",
    "        continue  # Skip to the next iteration of the loop\n",
    "\n",
    "# Add the RMSE values to the station_details DataFrame\n",
    "station_details['RMSE'] = rmse_values\n",
    "\n",
    "# Save the updated dataframe as \"rmse_saral.csv\"\n",
    "station_details.to_csv('rmse_swot_surge_with.csv', index=False)\n",
    "\n",
    "# Close the NetCDF file\n",
    "nc_file.close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adcsat-cfgrib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
